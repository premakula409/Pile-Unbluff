# -*- coding: utf-8 -*-
"""SmartLibraryGrok.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1TxRPAS0rrFhg_FDhbwTg-igp8QobP1
"""

!pip install gensim

# Install necessary libraries
!pip install gensim
!pip install gradio

# Import necessary libraries
import pandas as pd
import numpy as np
from google.colab import drive
import gensim.downloader as api
from sklearn.metrics.pairwise import cosine_similarity
import gradio as gr
import re
from nltk.corpus import stopwords
import nltk

# Mount Google Drive to access the dataset
drive.mount('/content/drive')

# Load the dataset from Google Drive
file_path = "/content/drive/MyDrive/Colab Notebooks/Smart_Library_Dataset.csv"
df = pd.read_csv(file_path)

# Download NLTK stop words for text cleaning
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Define a function to clean the text (lowercase, remove punctuation, remove stop words)
def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove punctuation
    text = ' '.join(word for word in text.split() if word not in stop_words)  # Remove stop words
    return text

# Combine 'Book Name' and 'Keywords' into 'Text' and preprocess it
df['Text'] = df['Book Name'] + " " + df['Keywords']
df['Text'] = df['Text'].apply(preprocess_text)

# Load pre-trained Word2Vec model (this might take a few minutes)
print("Loading Word2Vec model... This may take a moment.")
wv = api.load('word2vec-google-news-300')
print("Model loaded successfully.")

# Define a function to compute the average word embedding for a given text
def get_average_embedding(text):
    words = text.split()
    embeddings = [wv[word] for word in words if word in wv]  # Get embeddings for words in the model
    if embeddings:
        return np.mean(embeddings, axis=0)  # Average the embeddings
    else:
        return np.zeros(300)  # Return zero vector if no words are found

# Compute the average word embeddings for each book's text
book_embeddings = np.array([get_average_embedding(text) for text in df['Text']])

# Define the search function to recommend top N books based on query
def recommend_books(query, n=3, threshold=0.1):
    query = preprocess_text(query)  # Clean the query
    query_embedding = get_average_embedding(query)  # Get embedding for query
    if np.all(query_embedding == 0):
        return "No relevant books found."  # If query has no known words
    similarities = cosine_similarity([query_embedding], book_embeddings)[0]  # Compute similarities
    top_indices = similarities.argsort()[-n:][::-1]  # Get indices of top N similar books
    results = []
    for idx in top_indices:
        if similarities[idx] >= threshold:  # Only include books above the threshold
            book = df.iloc[idx]
            results.append(f"ðŸ“š {book['Book Name']} (Rack {book['Rack']}, Row {book['Row']})")
    if results:
        return "\n".join(results)  # Return formatted results
    else:
        return "No relevant books found."

# Create and launch the Gradio interface
gr.Interface(fn=recommend_books, inputs="text", outputs="text",
             title="Smart Library Book Finder",
             description="Enter keywords to find books!").launch()